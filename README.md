Machine Learning Datasets

Machine Learning Preprocessing & Model Benchmark Study

This project presents a complete experimental comparison of data preprocessing techniques and machine learning models across multiple datasets.

The goal of this study is to determine:

âœ… Best missing value handling strategy

âœ… Best encoding technique

âœ… Best class imbalance method

âœ… Best scaling approach

âœ… Best classification model

âœ… Best regression model

All strategies were evaluated using proper performance metrics and cross-validation.

ğŸ“Œ Project Structure

The experiments are divided into:

Missing Value Handling

Encoding Techniques

Label Distribution Handling

Classification Models

Regression Models

Feature Scaling

Each dataset was tested independently.

ğŸ”¹ 1ï¸âƒ£ Missing Value Handling
Strategies Tested

Drop rows

Mean imputation

Median imputation

KNN imputation

Forward fill (ffill)

Backward fill (bfill)

âœ… Best Strategy Per Dataset
Dataset	Best Strategy
data_1	Mean
data_2	Median
data_3	KNN
data_4	Drop
ğŸ” Observations

Mean works well for normally distributed data.

Median is more robust to outliers.

KNN performs best when feature relationships are complex.

Drop works when imputation introduces heavy distortion.

ğŸ”¹ 2ï¸âƒ£ Encoding Techniques
Strategies Tested

Ordinal Encoding

One-Hot Encoding

âœ… Best Encoding
Dataset	Best Encoding
data_1	Ordinal
data_2	One-Hot
ğŸ” Observations

If categorical variables have order â†’ Ordinal works better.

If categorical variables are nominal â†’ One-Hot performs better.

ğŸ”¹ 3ï¸âƒ£ Label Distribution Handling
Strategies Tested

None

Under-sampling

Over-sampling

SMOTE

Class Weights

âœ… Best Strategy
Dataset	Best Strategy
data_1	None
data_2	None
data_3	None
data_4	Weights
ğŸ” Observations

Data_1, Data_2, Data_3 were not heavily imbalanced.

Data_4 was clearly imbalanced â†’ Class weights improved Recall and F1-score significantly.

ğŸ”¹ 4ï¸âƒ£ Classification Models
Models Tested

Logistic Regression

KNN

SVM

Decision Tree

âœ… Best Classification Model
Dataset	Best Model
data_4	Logistic Regression
data_5	KNN
data_6	SVM
data_7	Decision Tree
ğŸ” Observations

Logistic â†’ Best for linear separable data

KNN â†’ Excellent for clustered data

SVM â†’ Strong for smooth nonlinear boundaries

Decision Tree â†’ Best for rule-based splits

ğŸ”¹ 5ï¸âƒ£ Regression Models
Models Tested

Linear Regression

KNN Regressor

SVM Regressor

Decision Tree Regressor

âœ… Best Regression Model
Dataset	Best Model
data_1	Linear Regression
data_2	Decision Tree
data_3	SVM
ğŸ” Observations

Data_1 shows strong linear structure.

Data_2 is highly nonlinear.

Data_3 has complex nonlinear smooth patterns.

ğŸ”¹ 6ï¸âƒ£ Feature Scaling
Strategies Tested

None

Min-Max Scaling

Standard Scaling

âœ… Best Scaling
Dataset	Best Scaling
data_1	Min-Max (or Standard)
data_2	None
data_3	Standard
ğŸ” Observations

Linear and SVM models are sensitive to scaling.

Tree-based models are scale invariant.

Always test scaling based on model type.

ğŸ“Š Key Takeaways

âœ” There is no universal best preprocessing method.
âœ” Dataset characteristics determine optimal strategy.
âœ” Model selection must match data structure.
âœ” Preprocessing has a major impact on performance.
âœ” Always evaluate using proper metrics.

ğŸ§  Final Summary
Category	Key Insight
Missing Values	Strategy depends on distribution & data quality
Encoding	Choose based on ordinal vs nominal nature
Imbalance	Use weights only when dataset is skewed
Scaling	Required for linear & distance-based models
Model Choice	Depends on linear vs nonlinear structure
ğŸš€ Conclusion

This project demonstrates the importance of:

Careful preprocessing

Systematic experimentation

Metric-based comparison

Understanding dataset behavior before model selection
